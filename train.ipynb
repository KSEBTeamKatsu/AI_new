{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadabde2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c2309a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # 선형 대수 연산용\n",
    "import pandas as pd # 데이터 처리, CSV 파일 입출력용 (예: pd.read_csv)\n",
    "# 현재 디렉토리(/kaggle/working/)에는 최대 20GB까지 파일을 저장할 수 있으며,\n",
    "# \"Save & Run All\" 기능을 사용하여 버전을 만들 때 출력 결과로 보존됩니다\n",
    "# 또한 /kaggle/temp/ 디렉토리에는 임시 파일을 저장할 수 있으나,\n",
    "# 이 파일들은 현재 세션이 종료되면 저장되지 않습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d422cacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  # 운영 체제와 상호작용하기 위한 모듈 (예: 파일 경로 설정, 디렉터리 생성 등)\n",
    "\n",
    "import tensorflow as tf  # 구글에서 만든 딥러닝 라이브러리 TensorFlow를 불러옴\n",
    "from tensorflow import keras  # TensorFlow 안에 포함된 고수준 딥러닝 API인 Keras를 불러옴\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam  # 모델 학습 시 사용하는 최적화 알고리즘 중 하나인 Adam 불러옴\n",
    "\n",
    "from sklearn.model_selection import train_test_split  # 데이터를 학습용과 테스트용으로 나누기 위한 함수\n",
    "\n",
    "from tensorflow.keras.metrics import categorical_crossentropy  # 다중 분류 문제에서 사용되는 손실 함수 (정답과 예측 차이 계산)\n",
    "\n",
    "from tensorflow.keras.models import Model, load_model, Sequential  # Keras의 모델 관련 기능 불러옴 (Model: 기본 모델, load_model: 저장된 모델 불러오기, Sequential: 레이어를 순서대로 쌓는 모델)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report  # 모델의 성능 평가에 사용되는 도구 (혼동 행렬, 정확도 등)\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator  # 이미지 데이터를 증강(늘리기)하기 위한 도구 (회전, 확대, 이동 등으로 이미지 다양화)\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout, BatchNormalization  \n",
    "# Conv2D: 이미지 특징을 추출하는 필터 레이어  \n",
    "# MaxPooling2D: 이미지 크기를 줄이면서 중요한 특징만 남기는 레이어  \n",
    "# Flatten: 2D 이미지를 1D로 펴주는 레이어 (Dense 레이어 입력을 위해 필요)  \n",
    "# Dense: 완전 연결된 레이어 (신경망의 기본 구조)  \n",
    "# Activation: 활성화 함수 적용 (예: ReLU, Softmax 등)  \n",
    "# Dropout: 과적합을 막기 위해 일부 뉴런을 학습 중 무시하는 기법  \n",
    "# BatchNormalization: 학습 속도 향상 및 안정화를 위한 정규화 레이어\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64cb2b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 2\n",
      "Target Names: ['apples', 'tomatoes']\n"
     ]
    }
   ],
   "source": [
    "import os  # 운영체제 기능을 사용하기 위한 모듈을 불러옴 (예: 폴더 경로 탐색 등)\n",
    "\n",
    "# 데이터셋이 저장된 폴더 경로를 지정함\n",
    "fpath = \"./archive/train\"\n",
    "dataset_path = fpath  # 위에서 지정한 경로를 dataset_path 변수에 저장\n",
    "\n",
    "# 폴더 안에 있는 하위 디렉토리 목록을 가져옴 (각 디렉토리는 한 개의 클래스에 해당됨)\n",
    "class_folders = [f.name for f in os.scandir(dataset_path) if f.is_dir()]  \n",
    "# 예: 'apple', 'tomato'라는 폴더가 있다면 ['apple', 'tomato'] 반환\n",
    "\n",
    "# 클래스(분류할 대상)의 개수를 계산함\n",
    "num_classes = len(class_folders)  # 위에서 찾은 폴더 개수만큼 클래스 수가 정해짐\n",
    "\n",
    "# 클래스의 개수를 출력함\n",
    "print(\"Number of classes:\", num_classes)  # 예: Number of classes: 2\n",
    "\n",
    "# 클래스 이름들을 리스트로 저장 (예: ['apple', 'tomato'])\n",
    "target_names = class_folders  # 예측 결과를 사람이 이해할 수 있도록 이름으로 저장\n",
    "\n",
    "# 클래스 이름 리스트를 출력함\n",
    "print(\"Target Names:\", target_names)  # 예: Target Names: ['apple', 'tomato']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "151ffdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 224\n",
    "batch_size =50\n",
    "fpath = \"./archive/train\"\n",
    "ffpath=\"./archive/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c24a69f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 236 images belonging to 2 classes.\n",
      "Found 58 images belonging to 2 classes.\n",
      "Found 97 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator  # 이미지 데이터 증강을 위한 도구를 불러옴 (회전, 확대, 정규화 등)\n",
    "\n",
    "# 'fpath'는 학습용 데이터셋 폴더 경로이고, 'batch_size'는 한 번에 불러올 이미지 수라고 가정\n",
    "\n",
    "# 학습 및 검증 데이터를 전처리하고, 이미지 증강을 설정함\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1/255.,              # 픽셀 값을 0~255 → 0~1로 정규화 (모델 학습에 적합하게 만듦)\n",
    "    zoom_range=0.2,              # 이미지를 랜덤하게 최대 20%까지 확대\n",
    "    rotation_range=30,          # 이미지를 -30도~+30도 사이로 회전시킴\n",
    "    validation_split=0.2,       # 전체 데이터 중 20%는 검증용(validation)으로 사용\n",
    "    horizontal_flip=True        # 이미지를 좌우로 뒤집는 데이터 증강 적용\n",
    ")\n",
    "\n",
    "# 학습용 이미지 생성기 설정\n",
    "train_gen = datagen.flow_from_directory(\n",
    "    fpath,                      # 이미지가 저장된 최상위 폴더 경로\n",
    "    target_size=(224, 224),     # 모든 이미지를 224x224 크기로 맞춤 (모델 입력 크기)\n",
    "    subset=\"training\",          # 전체 중 80%를 학습용으로 사용\n",
    "    class_mode='categorical',   # 다중 클래스 분류이므로 one-hot 인코딩된 label 사용\n",
    "    batch_size=batch_size       # 한 번에 불러올 이미지 개수 (성능과 속도에 영향을 줌)\n",
    ")\n",
    "\n",
    "# 검증용 이미지 생성기 설정\n",
    "valid_gen = datagen.flow_from_directory(\n",
    "    fpath,                      # 같은 폴더에서 검증용 이미지도 불러옴\n",
    "    target_size=(224, 224),     # 이미지 크기 통일\n",
    "    batch_size=batch_size,      # 배치 크기 동일하게 설정\n",
    "    subset='validation',        # 전체 중 20%를 검증용으로 사용\n",
    "    class_mode='categorical'    # 다중 분류를 위한 one-hot 인코딩\n",
    ")\n",
    "\n",
    "# 테스트용 데이터 생성기 설정\n",
    "test_gen = ImageDataGenerator(rescale=1/255.).flow_from_directory(\n",
    "    ffpath,                     # 테스트 이미지가 저장된 폴더 경로 (오타 주의: fpath와 다름)\n",
    "    target_size=(224, 224),     # 테스트 이미지도 크기를 동일하게 맞춤\n",
    "    batch_size=50,              # 한 번에 50장의 이미지를 불러옴\n",
    "    class_mode='categorical',   # 다중 클래스 분류용 설정\n",
    "    shuffle=False               # 테스트에서는 결과를 정확히 비교해야 하므로 셔플 비활성화\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32a2b110",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 60\u001b[39m\n\u001b[32m     51\u001b[39m checkpoint = ModelCheckpoint(\n\u001b[32m     52\u001b[39m     filepath,                \u001b[38;5;66;03m# 저장 파일 경로\u001b[39;00m\n\u001b[32m     53\u001b[39m     monitor=\u001b[33m'\u001b[39m\u001b[33mval_accuracy\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;66;03m# 검증 데이터의 정확도를 기준으로 판단\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     56\u001b[39m     mode=\u001b[33m'\u001b[39m\u001b[33mmax\u001b[39m\u001b[33m'\u001b[39m              \u001b[38;5;66;03m# 최대값이 가장 좋은 성능으로 간주\u001b[39;00m\n\u001b[32m     57\u001b[39m )\n\u001b[32m     59\u001b[39m \u001b[38;5;66;03m# 모델을 학습하고, 콜백을 적용하여 최적의 모델을 자동으로 저장함\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# 학습 데이터 생성기\u001b[39;49;00m\n\u001b[32m     62\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;66;43;03m# 전체 데이터셋을 20번 반복 학습\u001b[39;49;00m\n\u001b[32m     63\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;66;43;03m# 학습 과정을 자세히 출력\u001b[39;49;00m\n\u001b[32m     64\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalid_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 검증용 데이터 생성기\u001b[39;49;00m\n\u001b[32m     65\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m]\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;66;43;03m# 체크포인트 콜백을 적용하여 모델 저장\u001b[39;49;00m\n\u001b[32m     66\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hyuk\\anaconda3\\envs\\SML\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hyuk\\anaconda3\\envs\\SML\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:332\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    325\u001b[39m     (\n\u001b[32m    326\u001b[39m         val_x,\n\u001b[32m    327\u001b[39m         val_y,\n\u001b[32m    328\u001b[39m         val_sample_weight,\n\u001b[32m    329\u001b[39m     ) = data_adapter_utils.unpack_x_y_sample_weight(validation_data)\n\u001b[32m    331\u001b[39m \u001b[38;5;66;03m# Create an iterator that yields batches for one epoch.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m332\u001b[39m epoch_iterator = \u001b[43mTFEpochIterator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    334\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    337\u001b[39m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m=\u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    338\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    339\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    340\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdistribute_strategy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdistribute_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    341\u001b[39m \u001b[43m    \u001b[49m\u001b[43msteps_per_execution\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msteps_per_execution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    342\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    344\u001b[39m \u001b[38;5;28mself\u001b[39m._maybe_symbolic_build(iterator=epoch_iterator)\n\u001b[32m    345\u001b[39m epoch_iterator.reset()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hyuk\\anaconda3\\envs\\SML\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:720\u001b[39m, in \u001b[36mTFEpochIterator.__init__\u001b[39m\u001b[34m(self, distribute_strategy, *args, **kwargs)\u001b[39m\n\u001b[32m    718\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(*args, **kwargs)\n\u001b[32m    719\u001b[39m \u001b[38;5;28mself\u001b[39m._distribute_strategy = distribute_strategy\n\u001b[32m--> \u001b[39m\u001b[32m720\u001b[39m dataset = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata_adapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_tf_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    721\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dataset, tf.distribute.DistributedDataset):\n\u001b[32m    722\u001b[39m     dataset = \u001b[38;5;28mself\u001b[39m._distribute_strategy.experimental_distribute_dataset(\n\u001b[32m    723\u001b[39m         dataset\n\u001b[32m    724\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hyuk\\anaconda3\\envs\\SML\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:290\u001b[39m, in \u001b[36mPyDatasetAdapter.get_tf_dataset\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    288\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m num_batches \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    289\u001b[39m     num_samples = \u001b[38;5;28mmin\u001b[39m(num_samples, num_batches)\n\u001b[32m--> \u001b[39m\u001b[32m290\u001b[39m batches = \u001b[43m[\u001b[49m\n\u001b[32m    291\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_standardize_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpy_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    292\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    293\u001b[39m \u001b[43m\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    294\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(batches) == \u001b[32m0\u001b[39m:\n\u001b[32m    295\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mThe PyDataset has length 0\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hyuk\\anaconda3\\envs\\SML\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:291\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    288\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m num_batches \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    289\u001b[39m     num_samples = \u001b[38;5;28mmin\u001b[39m(num_samples, num_batches)\n\u001b[32m    290\u001b[39m batches = [\n\u001b[32m--> \u001b[39m\u001b[32m291\u001b[39m     \u001b[38;5;28mself\u001b[39m._standardize_batch(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpy_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[32m    292\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_samples)\n\u001b[32m    293\u001b[39m ]\n\u001b[32m    294\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(batches) == \u001b[32m0\u001b[39m:\n\u001b[32m    295\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mThe PyDataset has length 0\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hyuk\\anaconda3\\envs\\SML\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:68\u001b[39m, in \u001b[36mIterator.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m     64\u001b[39m     \u001b[38;5;28mself\u001b[39m._set_index_array()\n\u001b[32m     65\u001b[39m index_array = \u001b[38;5;28mself\u001b[39m.index_array[\n\u001b[32m     66\u001b[39m     \u001b[38;5;28mself\u001b[39m.batch_size * idx : \u001b[38;5;28mself\u001b[39m.batch_size * (idx + \u001b[32m1\u001b[39m)\n\u001b[32m     67\u001b[39m ]\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_batches_of_transformed_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex_array\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hyuk\\anaconda3\\envs\\SML\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:327\u001b[39m, in \u001b[36mBatchFromFilesMixin._get_batches_of_transformed_samples\u001b[39m\u001b[34m(self, index_array)\u001b[39m\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.image_data_generator:\n\u001b[32m    326\u001b[39m     params = \u001b[38;5;28mself\u001b[39m.image_data_generator.get_random_transform(x.shape)\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mimage_data_generator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    328\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.image_data_generator.standardize(x)\n\u001b[32m    329\u001b[39m batch_x[i] = x\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hyuk\\anaconda3\\envs\\SML\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:1413\u001b[39m, in \u001b[36mImageDataGenerator.apply_transform\u001b[39m\u001b[34m(self, x, transform_parameters)\u001b[39m\n\u001b[32m   1410\u001b[39m img_col_axis = \u001b[38;5;28mself\u001b[39m.col_axis - \u001b[32m1\u001b[39m\n\u001b[32m   1411\u001b[39m img_channel_axis = \u001b[38;5;28mself\u001b[39m.channel_axis - \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1413\u001b[39m x = \u001b[43mapply_affine_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1414\u001b[39m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1415\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtransform_parameters\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtheta\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1416\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtransform_parameters\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtx\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1417\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtransform_parameters\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1418\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtransform_parameters\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mshear\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1419\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtransform_parameters\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mzx\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1420\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtransform_parameters\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mzy\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1421\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrow_axis\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimg_row_axis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1422\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcol_axis\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimg_col_axis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1423\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchannel_axis\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimg_channel_axis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1424\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfill_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfill_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1425\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcval\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1426\u001b[39m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minterpolation_order\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1427\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1429\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m transform_parameters.get(\u001b[33m\"\u001b[39m\u001b[33mchannel_shift_intensity\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1430\u001b[39m     x = apply_channel_shift(\n\u001b[32m   1431\u001b[39m         x,\n\u001b[32m   1432\u001b[39m         transform_parameters[\u001b[33m\"\u001b[39m\u001b[33mchannel_shift_intensity\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   1433\u001b[39m         img_channel_axis,\n\u001b[32m   1434\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hyuk\\anaconda3\\envs\\SML\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:1879\u001b[39m, in \u001b[36mapply_affine_transform\u001b[39m\u001b[34m(x, theta, tx, ty, shear, zx, zy, row_axis, col_axis, channel_axis, fill_mode, cval, order)\u001b[39m\n\u001b[32m   1876\u001b[39m final_affine_matrix = transform_matrix[:\u001b[32m2\u001b[39m, :\u001b[32m2\u001b[39m]\n\u001b[32m   1877\u001b[39m final_offset = transform_matrix[:\u001b[32m2\u001b[39m, \u001b[32m2\u001b[39m]\n\u001b[32m-> \u001b[39m\u001b[32m1879\u001b[39m channel_images = \u001b[43m[\u001b[49m\n\u001b[32m   1880\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscipy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mndimage\u001b[49m\u001b[43m.\u001b[49m\u001b[43minterpolation\u001b[49m\u001b[43m.\u001b[49m\u001b[43maffine_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx_channel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfinal_affine_matrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfinal_offset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m        \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfill_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx_channel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m   1890\u001b[39m x = np.stack(channel_images, axis=\u001b[32m0\u001b[39m)\n\u001b[32m   1891\u001b[39m x = np.rollaxis(x, \u001b[32m0\u001b[39m, channel_axis + \u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hyuk\\anaconda3\\envs\\SML\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:1880\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m   1876\u001b[39m final_affine_matrix = transform_matrix[:\u001b[32m2\u001b[39m, :\u001b[32m2\u001b[39m]\n\u001b[32m   1877\u001b[39m final_offset = transform_matrix[:\u001b[32m2\u001b[39m, \u001b[32m2\u001b[39m]\n\u001b[32m   1879\u001b[39m channel_images = [\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m     \u001b[43mscipy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mndimage\u001b[49m\u001b[43m.\u001b[49m\u001b[43minterpolation\u001b[49m\u001b[43m.\u001b[49m\u001b[43maffine_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx_channel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfinal_affine_matrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfinal_offset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m        \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfill_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1888\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m x_channel \u001b[38;5;129;01min\u001b[39;00m x\n\u001b[32m   1889\u001b[39m ]\n\u001b[32m   1890\u001b[39m x = np.stack(channel_images, axis=\u001b[32m0\u001b[39m)\n\u001b[32m   1891\u001b[39m x = np.rollaxis(x, \u001b[32m0\u001b[39m, channel_axis + \u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hyuk\\anaconda3\\envs\\SML\\Lib\\site-packages\\scipy\\ndimage\\_interpolation.py:628\u001b[39m, in \u001b[36maffine_transform\u001b[39m\u001b[34m(input, matrix, offset, output_shape, output, order, mode, cval, prefilter)\u001b[39m\n\u001b[32m    625\u001b[39m     _nd_image.zoom_shift(filtered, matrix, offset/matrix, output, order,\n\u001b[32m    626\u001b[39m                          mode, cval, npad, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    627\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m628\u001b[39m     \u001b[43m_nd_image\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgeometric_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiltered\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    629\u001b[39m \u001b[43m                                  \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnpad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    630\u001b[39m \u001b[43m                                  \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    631\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf  # 텐서플로(TensorFlow)는 딥러닝을 구현할 수 있는 구글의 오픈소스 프레임워크\n",
    "from tensorflow.keras.models import Sequential  # 레이어를 순차적으로 쌓을 수 있는 간단한 모델 형식\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization  # 완전 연결층(Dense), 과적합 방지용 드롭아웃, 학습 안정화를 위한 배치 정규화 레이어\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint  # 모델을 저장할 수 있는 콜백 함수 불러오기\n",
    "\n",
    "# train_gen과 valid_gen은 이미지 데이터 생성기라고 가정 (학습용과 검증용 이미지)\n",
    "\n",
    "img_size = (224, 224)  # 이미지의 크기를 224x224로 설정 (입력으로 통일된 크기 사용)\n",
    "channels = 3  # 컬러 이미지이므로 R, G, B 채널로 총 3개\n",
    "img_shape = (img_size[0], img_size[1], channels)  # 전체 입력 이미지의 형태 (224, 224, 3)\n",
    "\n",
    "class_count = len(list(train_gen.class_indices.keys()))  # 분류해야 할 클래스(카테고리) 수를 계산함\n",
    "\n",
    "# 사전 학습된 모델(EfficientNetB3)을 불러옴\n",
    "base_model = tf.keras.applications.EfficientNetB3(\n",
    "    include_top=False,  # 기본 모델의 마지막 분류 레이어는 제거\n",
    "    weights=\"imagenet\",  # ImageNet 데이터로 학습된 가중치를 사용\n",
    "    input_shape=img_shape,  # 입력 이미지의 크기를 지정\n",
    "    pooling='max'  # 마지막 특성 맵을 전역 최대값으로 압축\n",
    ")\n",
    "\n",
    "# 사전학습된 레이어들의 가중치를 고정시켜 학습되지 않도록 설정\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False  # 가중치 업데이트를 하지 않도록 설정 (특징 추출용으로만 사용)\n",
    "\n",
    "# 전체 모델 구성: 사전학습 모델 위에 새 레이어들을 쌓아 최종 분류 모델 생성\n",
    "model = Sequential([\n",
    "    base_model,                         # 사전학습된 베이스 모델\n",
    "    BatchNormalization(),              # 학습 안정화를 위한 배치 정규화\n",
    "    Dense(256, activation='relu'),     # 은닉층 256개 뉴런, 활성화 함수는 ReLU\n",
    "    Dropout(0.3),                      # 학습 중 30% 뉴런을 비활성화하여 과적합 방지\n",
    "    Dense(64, activation='relu'),      # 또 다른 은닉층 64개 뉴런\n",
    "    Dropout(0.3),                      # 과적합 방지를 위한 드롭아웃\n",
    "    Dense(class_count, activation='softmax')  # 출력층: 클래스 수만큼 뉴런, 확률값을 출력하기 위해 softmax 사용\n",
    "])\n",
    "\n",
    "# 모델 학습을 위한 최적화 알고리즘(Adam) 설정\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "# 모델 컴파일: 손실 함수, 최적화 알고리즘, 평가 지표 설정\n",
    "model.compile(\n",
    "    optimizer=optimizer,                     # 위에서 정의한 Adam 최적화기 사용\n",
    "    loss='categorical_crossentropy',         # 다중 분류이므로 범주형 크로스 엔트로피 사용\n",
    "    metrics=['accuracy']                     # 모델 성능을 정확도로 평가\n",
    ")\n",
    "\n",
    "# 모델을 저장할 파일 경로 지정\n",
    "filepath = 'best_model.h5'  # 가장 성능이 좋은 모델을 이 파일명으로 저장함\n",
    "\n",
    "# 검증 정확도를 기준으로 가장 좋은 모델만 저장하는 콜백 정의\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath,                # 저장 파일 경로\n",
    "    monitor='val_accuracy', # 검증 데이터의 정확도를 기준으로 판단\n",
    "    verbose=1,              # 저장 여부를 콘솔에 출력함\n",
    "    save_best_only=True,    # 정확도가 가장 높을 때만 저장\n",
    "    mode='max'              # 최대값이 가장 좋은 성능으로 간주\n",
    ")\n",
    "\n",
    "# 모델을 학습하고, 콜백을 적용하여 최적의 모델을 자동으로 저장함\n",
    "history = model.fit(\n",
    "    x=train_gen,            # 학습 데이터 생성기\n",
    "    epochs=2000,              # 전체 데이터셋을 20번 반복 학습\n",
    "    verbose=1,              # 학습 과정을 자세히 출력\n",
    "    validation_data=valid_gen,  # 검증용 데이터 생성기\n",
    "    callbacks=[checkpoint]      # 체크포인트 콜백을 적용하여 모델 저장\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaec5fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.layers import Input, Average\n",
    "\n",
    "\n",
    "\n",
    "model= load_model('best_model.h5')\n",
    "\n",
    "train_score = model.evaluate(train_gen, steps= len(train_gen), verbose= 1)\n",
    "valid_score = model.evaluate(valid_gen, steps= len(valid_gen), verbose= 1)\n",
    "test_score = model.evaluate(test_gen, steps= len(test_gen), verbose= 1)\n",
    "\n",
    "print(\"Train Loss: \", train_score[0])\n",
    "print(\"Train Accuracy: \", train_score[1])\n",
    "print('-' * 20)\n",
    "print(\"Validation Loss: \", valid_score[0])\n",
    "print(\"Validation Accuracy: \", valid_score[1])\n",
    "print('-' * 20)\n",
    "print(\"Test Loss: \", test_score[0])\n",
    "print(\"Test Accuracy: \", test_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2517bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('best_model.h5')\n",
    "preds = model.predict_generator(test_gen)\n",
    "y_pred = np.argmax(preds, axis=1)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafb8c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_confusion_matrix(cm, classes, normalize= False, title= 'Confusion Matrix', cmap= plt.cm.Blues):\n",
    "    plt.figure(figsize= (10, 10))\n",
    "    plt.imshow(cm, interpolation= 'nearest', cmap= cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation= 45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis= 1)[:, np.newaxis]\n",
    "        print('Normalized Confusion Matrix')\n",
    "    else:\n",
    "        print('Confusion Matrix, Without Normalization')\n",
    "    print(cm)\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j], horizontalalignment= 'center', color= 'white' if cm[i, j] > thresh else 'black')\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f0ef18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(test_gen.classes, y_pred)\n",
    "plot_confusion_matrix(cm= cm, classes= target_names, title = 'Confusion Matrix')\n",
    "# Classification report\n",
    "print(classification_report(test_gen.classes, y_pred, target_names= target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2858e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Assuming train_gen and valid_gen are your image data generators\n",
    "\n",
    "img_size = (224, 224)\n",
    "channels = 3\n",
    "img_shape = (img_size[0], img_size[1], channels)\n",
    "class_count = len(list(train_gen.class_indices.keys()))\n",
    "\n",
    "# Create pre-trained model\n",
    "base_model = tf.keras.applications.ResNet50(include_top=False, weights=\"imagenet\", input_shape=img_shape, pooling='max')\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    BatchNormalization(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "     Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(class_count, activation='softmax')\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define filepath to save the best model\n",
    "filepath = 'best_model_resnet.h5'\n",
    "\n",
    "# Create ModelCheckpoint callback to save the best model based on validation accuracy\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "# Train the model with the added callback\n",
    "history = model.fit(\n",
    "    x=train_gen,\n",
    "    epochs=20,\n",
    "    verbose=1,\n",
    "    validation_data=valid_gen,\n",
    "    callbacks=[checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8381f311",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.layers import Input, Average\n",
    "\n",
    "\n",
    "\n",
    "model= load_model('best_model_resnet.h5')\n",
    "\n",
    "\n",
    "train_score = model.evaluate(train_gen, steps= len(train_gen), verbose= 1)\n",
    "valid_score = model.evaluate(valid_gen, steps= len(valid_gen), verbose= 1)\n",
    "test_score = model.evaluate(test_gen, steps= len(test_gen), verbose= 1)\n",
    "\n",
    "print(\"Train Loss: \", train_score[0])\n",
    "print(\"Train Accuracy: \", train_score[1])\n",
    "print('-' * 20)\n",
    "print(\"Validation Loss: \", valid_score[0])\n",
    "print(\"Validation Accuracy: \", valid_score[1])\n",
    "print('-' * 20)\n",
    "print(\"Test Loss: \", test_score[0])\n",
    "print(\"Test Accuracy: \", test_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2666be8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('best_model_resnet.h5')\n",
    "preds = model.predict_generator(test_gen)\n",
    "y_pred = np.argmax(preds, axis=1)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830ae005",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(test_gen.classes, y_pred)\n",
    "plot_confusion_matrix(cm= cm, classes= target_names, title = 'Confusion Matrix')\n",
    "# Classification report\n",
    "print(classification_report(test_gen.classes, y_pred, target_names= target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074fb25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Assuming train_gen and valid_gen are your image data generators\n",
    "\n",
    "img_size = (224, 224)\n",
    "channels = 3\n",
    "img_shape = (img_size[0], img_size[1], channels)\n",
    "class_count = len(list(train_gen.class_indices.keys()))\n",
    "\n",
    "# Create pre-trained model\n",
    "base_model = tf.keras.applications.VGG16(include_top=False, weights=\"imagenet\", input_shape=img_shape, pooling='max')\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    BatchNormalization(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "     Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(class_count, activation='softmax')\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define filepath to save the best model\n",
    "filepath = 'best_model_vgg.h5'\n",
    "\n",
    "# Create ModelCheckpoint callback to save the best model based on validation accuracy\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "# Train the model with the added callback\n",
    "history = model.fit(\n",
    "    x=train_gen,\n",
    "    epochs=20,\n",
    "    verbose=1,\n",
    "    validation_data=valid_gen,\n",
    "    callbacks=[checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9bb363",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.layers import Input, Average\n",
    "\n",
    "\n",
    "\n",
    "model= load_model('best_model_vgg.h5')\n",
    "\n",
    "\n",
    "train_score = model.evaluate(train_gen, steps= len(train_gen), verbose= 1)\n",
    "valid_score = model.evaluate(valid_gen, steps= len(valid_gen), verbose= 1)\n",
    "test_score = model.evaluate(test_gen, steps= len(test_gen), verbose= 1)\n",
    "\n",
    "print(\"Train Loss: \", train_score[0])\n",
    "print(\"Train Accuracy: \", train_score[1])\n",
    "print('-' * 20)\n",
    "print(\"Validation Loss: \", valid_score[0])\n",
    "print(\"Validation Accuracy: \", valid_score[1])\n",
    "print('-' * 20)\n",
    "print(\"Test Loss: \", test_score[0])\n",
    "print(\"Test Accuracy: \", test_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcce496f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('best_model_vgg.h5')\n",
    "preds = model.predict_generator(test_gen)\n",
    "y_pred = np.argmax(preds, axis=1)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b8e933",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(test_gen.classes, y_pred)\n",
    "plot_confusion_matrix(cm= cm, classes= target_names, title = 'Confusion Matrix')\n",
    "# Classification report\n",
    "print(classification_report(test_gen.classes, y_pred, target_names= target_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
