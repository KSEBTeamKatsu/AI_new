{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadabde2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c2309a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # 선형 대수 연산용\n",
    "import pandas as pd # 데이터 처리, CSV 파일 입출력용 (예: pd.read_csv)\n",
    "# 현재 디렉토리(/kaggle/working/)에는 최대 20GB까지 파일을 저장할 수 있으며,\n",
    "# \"Save & Run All\" 기능을 사용하여 버전을 만들 때 출력 결과로 보존됩니다\n",
    "# 또한 /kaggle/temp/ 디렉토리에는 임시 파일을 저장할 수 있으나,\n",
    "# 이 파일들은 현재 세션이 종료되면 저장되지 않습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d422cacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  # 운영 체제와 상호작용하기 위한 모듈 (예: 파일 경로 설정, 디렉터리 생성 등)\n",
    "\n",
    "import tensorflow as tf  # 구글에서 만든 딥러닝 라이브러리 TensorFlow를 불러옴\n",
    "from tensorflow import keras  # TensorFlow 안에 포함된 고수준 딥러닝 API인 Keras를 불러옴\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam  # 모델 학습 시 사용하는 최적화 알고리즘 중 하나인 Adam 불러옴\n",
    "\n",
    "from sklearn.model_selection import train_test_split  # 데이터를 학습용과 테스트용으로 나누기 위한 함수\n",
    "\n",
    "from tensorflow.keras.metrics import categorical_crossentropy  # 다중 분류 문제에서 사용되는 손실 함수 (정답과 예측 차이 계산)\n",
    "\n",
    "from tensorflow.keras.models import Model, load_model, Sequential  # Keras의 모델 관련 기능 불러옴 (Model: 기본 모델, load_model: 저장된 모델 불러오기, Sequential: 레이어를 순서대로 쌓는 모델)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report  # 모델의 성능 평가에 사용되는 도구 (혼동 행렬, 정확도 등)\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator  # 이미지 데이터를 증강(늘리기)하기 위한 도구 (회전, 확대, 이동 등으로 이미지 다양화)\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout, BatchNormalization  \n",
    "# Conv2D: 이미지 특징을 추출하는 필터 레이어  \n",
    "# MaxPooling2D: 이미지 크기를 줄이면서 중요한 특징만 남기는 레이어  \n",
    "# Flatten: 2D 이미지를 1D로 펴주는 레이어 (Dense 레이어 입력을 위해 필요)  \n",
    "# Dense: 완전 연결된 레이어 (신경망의 기본 구조)  \n",
    "# Activation: 활성화 함수 적용 (예: ReLU, Softmax 등)  \n",
    "# Dropout: 과적합을 막기 위해 일부 뉴런을 학습 중 무시하는 기법  \n",
    "# BatchNormalization: 학습 속도 향상 및 안정화를 위한 정규화 레이어\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64cb2b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 2\n",
      "Target Names: ['apples', 'tomatoes']\n"
     ]
    }
   ],
   "source": [
    "import os  # 운영체제 기능을 사용하기 위한 모듈을 불러옴 (예: 폴더 경로 탐색 등)\n",
    "\n",
    "# 데이터셋이 저장된 폴더 경로를 지정함\n",
    "fpath = \"./archive/train\"\n",
    "dataset_path = fpath  # 위에서 지정한 경로를 dataset_path 변수에 저장\n",
    "\n",
    "# 폴더 안에 있는 하위 디렉토리 목록을 가져옴 (각 디렉토리는 한 개의 클래스에 해당됨)\n",
    "class_folders = [f.name for f in os.scandir(dataset_path) if f.is_dir()]  \n",
    "# 예: 'apple', 'tomato'라는 폴더가 있다면 ['apple', 'tomato'] 반환\n",
    "\n",
    "# 클래스(분류할 대상)의 개수를 계산함\n",
    "num_classes = len(class_folders)  # 위에서 찾은 폴더 개수만큼 클래스 수가 정해짐\n",
    "\n",
    "# 클래스의 개수를 출력함\n",
    "print(\"Number of classes:\", num_classes)  # 예: Number of classes: 2\n",
    "\n",
    "# 클래스 이름들을 리스트로 저장 (예: ['apple', 'tomato'])\n",
    "target_names = class_folders  # 예측 결과를 사람이 이해할 수 있도록 이름으로 저장\n",
    "\n",
    "# 클래스 이름 리스트를 출력함\n",
    "print(\"Target Names:\", target_names)  # 예: Target Names: ['apple', 'tomato']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "151ffdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 224\n",
    "batch_size =50\n",
    "fpath = \"./archive/train\"\n",
    "ffpath=\"./archive/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c24a69f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 236 images belonging to 2 classes.\n",
      "Found 58 images belonging to 2 classes.\n",
      "Found 97 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator  # 이미지 데이터 증강을 위한 도구를 불러옴 (회전, 확대, 정규화 등)\n",
    "\n",
    "# 'fpath'는 학습용 데이터셋 폴더 경로이고, 'batch_size'는 한 번에 불러올 이미지 수라고 가정\n",
    "\n",
    "# 학습 및 검증 데이터를 전처리하고, 이미지 증강을 설정함\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1/255.,              # 픽셀 값을 0~255 → 0~1로 정규화 (모델 학습에 적합하게 만듦)\n",
    "    zoom_range=0.2,              # 이미지를 랜덤하게 최대 20%까지 확대\n",
    "    rotation_range=30,          # 이미지를 -30도~+30도 사이로 회전시킴\n",
    "    validation_split=0.2,       # 전체 데이터 중 20%는 검증용(validation)으로 사용\n",
    "    horizontal_flip=True        # 이미지를 좌우로 뒤집는 데이터 증강 적용\n",
    ")\n",
    "\n",
    "# 학습용 이미지 생성기 설정\n",
    "train_gen = datagen.flow_from_directory(\n",
    "    fpath,                      # 이미지가 저장된 최상위 폴더 경로\n",
    "    target_size=(224, 224),     # 모든 이미지를 224x224 크기로 맞춤 (모델 입력 크기)\n",
    "    subset=\"training\",          # 전체 중 80%를 학습용으로 사용\n",
    "    class_mode='categorical',   # 다중 클래스 분류이므로 one-hot 인코딩된 label 사용\n",
    "    batch_size=batch_size       # 한 번에 불러올 이미지 개수 (성능과 속도에 영향을 줌)\n",
    ")\n",
    "\n",
    "# 검증용 이미지 생성기 설정\n",
    "valid_gen = datagen.flow_from_directory(\n",
    "    fpath,                      # 같은 폴더에서 검증용 이미지도 불러옴\n",
    "    target_size=(224, 224),     # 이미지 크기 통일\n",
    "    batch_size=batch_size,      # 배치 크기 동일하게 설정\n",
    "    subset='validation',        # 전체 중 20%를 검증용으로 사용\n",
    "    class_mode='categorical'    # 다중 분류를 위한 one-hot 인코딩\n",
    ")\n",
    "\n",
    "# 테스트용 데이터 생성기 설정\n",
    "test_gen = ImageDataGenerator(rescale=1/255.).flow_from_directory(\n",
    "    ffpath,                     # 테스트 이미지가 저장된 폴더 경로 (오타 주의: fpath와 다름)\n",
    "    target_size=(224, 224),     # 테스트 이미지도 크기를 동일하게 맞춤\n",
    "    batch_size=50,              # 한 번에 50장의 이미지를 불러옴\n",
    "    class_mode='categorical',   # 다중 클래스 분류용 설정\n",
    "    shuffle=False               # 테스트에서는 결과를 정확히 비교해야 하므로 셔플 비활성화\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32a2b110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.5365 - loss: 1.1215\n",
      "Epoch 1: val_accuracy improved from -inf to 0.44828, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 7s/step - accuracy: 0.5431 - loss: 1.1089 - val_accuracy: 0.4483 - val_loss: 1.7192\n",
      "Epoch 2/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5387 - loss: 1.3265\n",
      "Epoch 2: val_accuracy improved from 0.44828 to 0.55172, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3s/step - accuracy: 0.5414 - loss: 1.3276 - val_accuracy: 0.5517 - val_loss: 2.2666\n",
      "Epoch 3/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6067 - loss: 1.1851\n",
      "Epoch 3: val_accuracy improved from 0.55172 to 0.56897, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.6073 - loss: 1.1877 - val_accuracy: 0.5690 - val_loss: 0.7042\n",
      "Epoch 4/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6075 - loss: 1.0948\n",
      "Epoch 4: val_accuracy did not improve from 0.56897\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.6066 - loss: 1.0940 - val_accuracy: 0.5517 - val_loss: 2.9924\n",
      "Epoch 5/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6163 - loss: 0.8780\n",
      "Epoch 5: val_accuracy did not improve from 0.56897\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - accuracy: 0.6174 - loss: 0.8793 - val_accuracy: 0.5517 - val_loss: 1.2037\n",
      "Epoch 6/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5737 - loss: 1.1316\n",
      "Epoch 6: val_accuracy did not improve from 0.56897\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4s/step - accuracy: 0.5749 - loss: 1.1252 - val_accuracy: 0.5517 - val_loss: 0.9332\n",
      "Epoch 7/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.5925 - loss: 1.0200\n",
      "Epoch 7: val_accuracy did not improve from 0.56897\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4s/step - accuracy: 0.5919 - loss: 1.0236 - val_accuracy: 0.5517 - val_loss: 1.0979\n",
      "Epoch 8/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6222 - loss: 0.9112\n",
      "Epoch 8: val_accuracy did not improve from 0.56897\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3s/step - accuracy: 0.6209 - loss: 0.9080 - val_accuracy: 0.4483 - val_loss: 0.8856\n",
      "Epoch 9/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5648 - loss: 0.9041\n",
      "Epoch 9: val_accuracy did not improve from 0.56897\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.5674 - loss: 0.8989 - val_accuracy: 0.5517 - val_loss: 0.7214\n",
      "Epoch 10/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5840 - loss: 0.8874\n",
      "Epoch 10: val_accuracy improved from 0.56897 to 0.60345, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3s/step - accuracy: 0.5792 - loss: 0.8873 - val_accuracy: 0.6034 - val_loss: 0.6702\n",
      "Epoch 11/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5924 - loss: 0.9317\n",
      "Epoch 11: val_accuracy did not improve from 0.60345\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.5869 - loss: 0.9235 - val_accuracy: 0.6034 - val_loss: 0.6735\n",
      "Epoch 12/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6177 - loss: 0.8056\n",
      "Epoch 12: val_accuracy did not improve from 0.60345\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - accuracy: 0.6164 - loss: 0.8081 - val_accuracy: 0.5862 - val_loss: 0.6768\n",
      "Epoch 13/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6551 - loss: 0.6867\n",
      "Epoch 13: val_accuracy did not improve from 0.60345\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - accuracy: 0.6525 - loss: 0.6941 - val_accuracy: 0.5690 - val_loss: 0.6714\n",
      "Epoch 14/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.6118 - loss: 0.6769\n",
      "Epoch 14: val_accuracy did not improve from 0.60345\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - accuracy: 0.6038 - loss: 0.6832 - val_accuracy: 0.4483 - val_loss: 0.7381\n",
      "Epoch 15/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5946 - loss: 0.7694\n",
      "Epoch 15: val_accuracy did not improve from 0.60345\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - accuracy: 0.5943 - loss: 0.7669 - val_accuracy: 0.4483 - val_loss: 0.7328\n",
      "Epoch 16/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5639 - loss: 0.7643\n",
      "Epoch 16: val_accuracy did not improve from 0.60345\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - accuracy: 0.5709 - loss: 0.7613 - val_accuracy: 0.5345 - val_loss: 0.6938\n",
      "Epoch 17/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5437 - loss: 0.7783\n",
      "Epoch 17: val_accuracy did not improve from 0.60345\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.5470 - loss: 0.7781 - val_accuracy: 0.6034 - val_loss: 0.6805\n",
      "Epoch 18/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6079 - loss: 0.7369\n",
      "Epoch 18: val_accuracy did not improve from 0.60345\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.6075 - loss: 0.7333 - val_accuracy: 0.5862 - val_loss: 0.6799\n",
      "Epoch 19/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5949 - loss: 0.7098\n",
      "Epoch 19: val_accuracy did not improve from 0.60345\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.5996 - loss: 0.7046 - val_accuracy: 0.5517 - val_loss: 0.6727\n",
      "Epoch 20/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6292 - loss: 0.6810\n",
      "Epoch 20: val_accuracy did not improve from 0.60345\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.6324 - loss: 0.6789 - val_accuracy: 0.6034 - val_loss: 0.6694\n",
      "Epoch 21/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5724 - loss: 0.8167\n",
      "Epoch 21: val_accuracy did not improve from 0.60345\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.5780 - loss: 0.8099 - val_accuracy: 0.5690 - val_loss: 0.6854\n",
      "Epoch 22/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7168 - loss: 0.6268\n",
      "Epoch 22: val_accuracy did not improve from 0.60345\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.7110 - loss: 0.6304 - val_accuracy: 0.5000 - val_loss: 0.6922\n",
      "Epoch 23/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5982 - loss: 0.6917\n",
      "Epoch 23: val_accuracy did not improve from 0.60345\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3s/step - accuracy: 0.5987 - loss: 0.6931 - val_accuracy: 0.5862 - val_loss: 0.6764\n",
      "Epoch 24/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6297 - loss: 0.6976\n",
      "Epoch 24: val_accuracy did not improve from 0.60345\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.6279 - loss: 0.7002 - val_accuracy: 0.5862 - val_loss: 0.6736\n",
      "Epoch 25/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5569 - loss: 0.7648\n",
      "Epoch 25: val_accuracy did not improve from 0.60345\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - accuracy: 0.5587 - loss: 0.7615 - val_accuracy: 0.4483 - val_loss: 0.6948\n",
      "Epoch 26/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6316 - loss: 0.6643\n",
      "Epoch 26: val_accuracy did not improve from 0.60345\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.6266 - loss: 0.6679 - val_accuracy: 0.4483 - val_loss: 0.6939\n",
      "Epoch 27/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5757 - loss: 0.6739\n",
      "Epoch 27: val_accuracy did not improve from 0.60345\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.5779 - loss: 0.6738 - val_accuracy: 0.5690 - val_loss: 0.6907\n",
      "Epoch 28/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6437 - loss: 0.6505\n",
      "Epoch 28: val_accuracy did not improve from 0.60345\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.6395 - loss: 0.6542 - val_accuracy: 0.5862 - val_loss: 0.6790\n",
      "Epoch 29/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6000 - loss: 0.6826\n",
      "Epoch 29: val_accuracy did not improve from 0.60345\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - accuracy: 0.6059 - loss: 0.6825 - val_accuracy: 0.5690 - val_loss: 0.6706\n",
      "Epoch 30/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6469 - loss: 0.6850\n",
      "Epoch 30: val_accuracy did not improve from 0.60345\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.6429 - loss: 0.6822 - val_accuracy: 0.5690 - val_loss: 0.6794\n",
      "Epoch 31/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7249 - loss: 0.6208\n",
      "Epoch 31: val_accuracy did not improve from 0.60345\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.7178 - loss: 0.6239 - val_accuracy: 0.5517 - val_loss: 0.7004\n",
      "Epoch 32/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6248 - loss: 0.6767\n",
      "Epoch 32: val_accuracy did not improve from 0.60345\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.6231 - loss: 0.6780 - val_accuracy: 0.5862 - val_loss: 0.6904\n",
      "Epoch 33/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6080 - loss: 0.6771\n",
      "Epoch 33: val_accuracy did not improve from 0.60345\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.6084 - loss: 0.6764 - val_accuracy: 0.5862 - val_loss: 0.6807\n",
      "Epoch 34/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5497 - loss: 0.7101\n",
      "Epoch 34: val_accuracy did not improve from 0.60345\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.5569 - loss: 0.7088 - val_accuracy: 0.5862 - val_loss: 0.6731\n",
      "Epoch 35/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6019 - loss: 0.6980\n",
      "Epoch 35: val_accuracy improved from 0.60345 to 0.62069, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.6054 - loss: 0.6946 - val_accuracy: 0.6207 - val_loss: 0.6712\n",
      "Epoch 36/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5785 - loss: 0.7007\n",
      "Epoch 36: val_accuracy did not improve from 0.62069\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.5830 - loss: 0.6987 - val_accuracy: 0.5690 - val_loss: 0.6737\n",
      "Epoch 37/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6427 - loss: 0.6273\n",
      "Epoch 37: val_accuracy did not improve from 0.62069\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3s/step - accuracy: 0.6415 - loss: 0.6283 - val_accuracy: 0.6034 - val_loss: 0.6655\n",
      "Epoch 38/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6368 - loss: 0.6414\n",
      "Epoch 38: val_accuracy did not improve from 0.62069\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3s/step - accuracy: 0.6359 - loss: 0.6433 - val_accuracy: 0.5862 - val_loss: 0.6697\n",
      "Epoch 39/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6453 - loss: 0.6275\n",
      "Epoch 39: val_accuracy did not improve from 0.62069\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.6430 - loss: 0.6312 - val_accuracy: 0.6034 - val_loss: 0.6608\n",
      "Epoch 40/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6921 - loss: 0.6364\n",
      "Epoch 40: val_accuracy improved from 0.62069 to 0.65517, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3s/step - accuracy: 0.6904 - loss: 0.6374 - val_accuracy: 0.6552 - val_loss: 0.6667\n",
      "Epoch 41/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6345 - loss: 0.6467\n",
      "Epoch 41: val_accuracy did not improve from 0.65517\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - accuracy: 0.6340 - loss: 0.6458 - val_accuracy: 0.5172 - val_loss: 0.6741\n",
      "Epoch 42/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6109 - loss: 0.6447\n",
      "Epoch 42: val_accuracy did not improve from 0.65517\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - accuracy: 0.6129 - loss: 0.6447 - val_accuracy: 0.5517 - val_loss: 0.6664\n",
      "Epoch 43/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6661 - loss: 0.6496\n",
      "Epoch 43: val_accuracy did not improve from 0.65517\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - accuracy: 0.6659 - loss: 0.6497 - val_accuracy: 0.6034 - val_loss: 0.6627\n",
      "Epoch 44/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6224 - loss: 0.6876\n",
      "Epoch 44: val_accuracy did not improve from 0.65517\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - accuracy: 0.6217 - loss: 0.6935 - val_accuracy: 0.5862 - val_loss: 0.6703\n",
      "Epoch 45/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.5872 - loss: 0.6739\n",
      "Epoch 45: val_accuracy did not improve from 0.65517\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4s/step - accuracy: 0.5889 - loss: 0.6756 - val_accuracy: 0.5862 - val_loss: 0.6765\n",
      "Epoch 46/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6312 - loss: 0.6397\n",
      "Epoch 46: val_accuracy did not improve from 0.65517\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3s/step - accuracy: 0.6270 - loss: 0.6419 - val_accuracy: 0.6034 - val_loss: 0.6757\n",
      "Epoch 47/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6132 - loss: 0.6194\n",
      "Epoch 47: val_accuracy did not improve from 0.65517\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3s/step - accuracy: 0.6170 - loss: 0.6173 - val_accuracy: 0.5517 - val_loss: 0.6710\n",
      "Epoch 48/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6939 - loss: 0.6316\n",
      "Epoch 48: val_accuracy did not improve from 0.65517\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - accuracy: 0.6913 - loss: 0.6320 - val_accuracy: 0.6034 - val_loss: 0.6700\n",
      "Epoch 49/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6578 - loss: 0.6535\n",
      "Epoch 49: val_accuracy did not improve from 0.65517\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3s/step - accuracy: 0.6618 - loss: 0.6514 - val_accuracy: 0.5862 - val_loss: 0.6642\n",
      "Epoch 50/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6025 - loss: 0.6680\n",
      "Epoch 50: val_accuracy did not improve from 0.65517\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3s/step - accuracy: 0.6003 - loss: 0.6705 - val_accuracy: 0.6034 - val_loss: 0.6543\n",
      "Epoch 51/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6264 - loss: 0.6874\n",
      "Epoch 51: val_accuracy did not improve from 0.65517\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - accuracy: 0.6286 - loss: 0.6829 - val_accuracy: 0.5690 - val_loss: 0.6693\n",
      "Epoch 52/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6549 - loss: 0.6420\n",
      "Epoch 52: val_accuracy improved from 0.65517 to 0.67241, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - accuracy: 0.6503 - loss: 0.6438 - val_accuracy: 0.6724 - val_loss: 0.6644\n",
      "Epoch 53/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5881 - loss: 0.6821\n",
      "Epoch 53: val_accuracy did not improve from 0.67241\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - accuracy: 0.5974 - loss: 0.6774 - val_accuracy: 0.6552 - val_loss: 0.6678\n",
      "Epoch 54/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6211 - loss: 0.6430\n",
      "Epoch 54: val_accuracy did not improve from 0.67241\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - accuracy: 0.6207 - loss: 0.6450 - val_accuracy: 0.6034 - val_loss: 0.6709\n",
      "Epoch 55/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6693 - loss: 0.6326\n",
      "Epoch 55: val_accuracy did not improve from 0.67241\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - accuracy: 0.6665 - loss: 0.6346 - val_accuracy: 0.6034 - val_loss: 0.6706\n",
      "Epoch 56/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6509 - loss: 0.6507\n",
      "Epoch 56: val_accuracy did not improve from 0.67241\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3s/step - accuracy: 0.6462 - loss: 0.6536 - val_accuracy: 0.6034 - val_loss: 0.6746\n",
      "Epoch 57/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6454 - loss: 0.6483\n",
      "Epoch 57: val_accuracy did not improve from 0.67241\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3s/step - accuracy: 0.6423 - loss: 0.6488 - val_accuracy: 0.5862 - val_loss: 0.6743\n",
      "Epoch 58/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6079 - loss: 0.6928\n",
      "Epoch 58: val_accuracy did not improve from 0.67241\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.6111 - loss: 0.6886 - val_accuracy: 0.6034 - val_loss: 0.6680\n",
      "Epoch 59/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6261 - loss: 0.6393\n",
      "Epoch 59: val_accuracy did not improve from 0.67241\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.6207 - loss: 0.6424 - val_accuracy: 0.6034 - val_loss: 0.6730\n",
      "Epoch 60/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6327 - loss: 0.6527\n",
      "Epoch 60: val_accuracy did not improve from 0.67241\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3s/step - accuracy: 0.6367 - loss: 0.6499 - val_accuracy: 0.5862 - val_loss: 0.6815\n",
      "Epoch 61/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6491 - loss: 0.6134\n",
      "Epoch 61: val_accuracy did not improve from 0.67241\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - accuracy: 0.6489 - loss: 0.6142 - val_accuracy: 0.5172 - val_loss: 0.6878\n",
      "Epoch 62/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.6436 - loss: 0.6481\n",
      "Epoch 62: val_accuracy did not improve from 0.67241\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4s/step - accuracy: 0.6401 - loss: 0.6510 - val_accuracy: 0.5862 - val_loss: 0.6783\n",
      "Epoch 63/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6517 - loss: 0.6465\n",
      "Epoch 63: val_accuracy did not improve from 0.67241\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3s/step - accuracy: 0.6504 - loss: 0.6485 - val_accuracy: 0.6034 - val_loss: 0.6695\n",
      "Epoch 64/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6314 - loss: 0.6470\n",
      "Epoch 64: val_accuracy did not improve from 0.67241\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - accuracy: 0.6335 - loss: 0.6489 - val_accuracy: 0.5517 - val_loss: 0.6800\n",
      "Epoch 65/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6408 - loss: 0.7035\n",
      "Epoch 65: val_accuracy did not improve from 0.67241\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4s/step - accuracy: 0.6414 - loss: 0.6972 - val_accuracy: 0.5690 - val_loss: 0.6834\n",
      "Epoch 66/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6553 - loss: 0.6269\n",
      "Epoch 66: val_accuracy did not improve from 0.67241\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3s/step - accuracy: 0.6528 - loss: 0.6271 - val_accuracy: 0.5862 - val_loss: 0.6741\n",
      "Epoch 67/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7021 - loss: 0.6023\n",
      "Epoch 67: val_accuracy did not improve from 0.67241\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3s/step - accuracy: 0.6945 - loss: 0.6076 - val_accuracy: 0.5862 - val_loss: 0.6767\n",
      "Epoch 68/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6176 - loss: 0.6349\n",
      "Epoch 68: val_accuracy did not improve from 0.67241\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3s/step - accuracy: 0.6157 - loss: 0.6386 - val_accuracy: 0.6034 - val_loss: 0.6644\n",
      "Epoch 69/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6571 - loss: 0.6439\n",
      "Epoch 69: val_accuracy did not improve from 0.67241\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4s/step - accuracy: 0.6570 - loss: 0.6436 - val_accuracy: 0.5690 - val_loss: 0.6740\n",
      "Epoch 70/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6324 - loss: 0.6635\n",
      "Epoch 70: val_accuracy did not improve from 0.67241\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3s/step - accuracy: 0.6322 - loss: 0.6632 - val_accuracy: 0.6207 - val_loss: 0.6654\n",
      "Epoch 71/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.5961 - loss: 0.6628\n",
      "Epoch 71: val_accuracy did not improve from 0.67241\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3s/step - accuracy: 0.6013 - loss: 0.6611 - val_accuracy: 0.5862 - val_loss: 0.6724\n",
      "Epoch 72/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.5934 - loss: 0.6668\n",
      "Epoch 72: val_accuracy did not improve from 0.67241\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4s/step - accuracy: 0.5976 - loss: 0.6630 - val_accuracy: 0.6034 - val_loss: 0.6714\n",
      "Epoch 73/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.7029 - loss: 0.5914\n",
      "Epoch 73: val_accuracy did not improve from 0.67241\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4s/step - accuracy: 0.6988 - loss: 0.5949 - val_accuracy: 0.5862 - val_loss: 0.6714\n",
      "Epoch 74/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6906 - loss: 0.6482\n",
      "Epoch 74: val_accuracy did not improve from 0.67241\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - accuracy: 0.6962 - loss: 0.6409 - val_accuracy: 0.5862 - val_loss: 0.6656\n",
      "Epoch 75/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6701 - loss: 0.6489\n",
      "Epoch 75: val_accuracy did not improve from 0.67241\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4s/step - accuracy: 0.6693 - loss: 0.6497 - val_accuracy: 0.5690 - val_loss: 0.6834\n",
      "Epoch 76/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.6718 - loss: 0.6185\n",
      "Epoch 76: val_accuracy did not improve from 0.67241\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4s/step - accuracy: 0.6657 - loss: 0.6241 - val_accuracy: 0.5690 - val_loss: 0.6777\n",
      "Epoch 77/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.6082 - loss: 0.6568\n",
      "Epoch 77: val_accuracy did not improve from 0.67241\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 5s/step - accuracy: 0.6107 - loss: 0.6594 - val_accuracy: 0.5345 - val_loss: 0.6938\n",
      "Epoch 78/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.6625 - loss: 0.6718\n",
      "Epoch 78: val_accuracy did not improve from 0.67241\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4s/step - accuracy: 0.6623 - loss: 0.6703 - val_accuracy: 0.4483 - val_loss: 0.6992\n",
      "Epoch 79/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5844 - loss: 0.6918\n",
      "Epoch 79: val_accuracy did not improve from 0.67241\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - accuracy: 0.5887 - loss: 0.6884 - val_accuracy: 0.5000 - val_loss: 0.6927\n",
      "Epoch 80/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5762 - loss: 0.6595\n",
      "Epoch 80: val_accuracy did not improve from 0.67241\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3s/step - accuracy: 0.5826 - loss: 0.6555 - val_accuracy: 0.4483 - val_loss: 0.6956\n",
      "Epoch 81/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6851 - loss: 0.6238\n",
      "Epoch 81: val_accuracy did not improve from 0.67241\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.6882 - loss: 0.6217 - val_accuracy: 0.4138 - val_loss: 0.7013\n",
      "Epoch 82/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6623 - loss: 0.6260\n",
      "Epoch 82: val_accuracy did not improve from 0.67241\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - accuracy: 0.6599 - loss: 0.6282 - val_accuracy: 0.4655 - val_loss: 0.6909\n",
      "Epoch 83/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6410 - loss: 0.6481\n",
      "Epoch 83: val_accuracy did not improve from 0.67241\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - accuracy: 0.6464 - loss: 0.6430 - val_accuracy: 0.6034 - val_loss: 0.6817\n",
      "Epoch 84/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7286 - loss: 0.5973\n",
      "Epoch 84: val_accuracy did not improve from 0.67241\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - accuracy: 0.7223 - loss: 0.5980 - val_accuracy: 0.6552 - val_loss: 0.6672\n",
      "Epoch 85/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6622 - loss: 0.6388\n",
      "Epoch 85: val_accuracy did not improve from 0.67241\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - accuracy: 0.6564 - loss: 0.6417 - val_accuracy: 0.5862 - val_loss: 0.6794\n",
      "Epoch 86/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6631 - loss: 0.6248\n",
      "Epoch 86: val_accuracy did not improve from 0.67241\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - accuracy: 0.6607 - loss: 0.6255 - val_accuracy: 0.6034 - val_loss: 0.6651\n",
      "Epoch 87/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5726 - loss: 0.7061\n",
      "Epoch 87: val_accuracy did not improve from 0.67241\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - accuracy: 0.5817 - loss: 0.7005 - val_accuracy: 0.5862 - val_loss: 0.6664\n",
      "Epoch 88/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7009 - loss: 0.5968\n",
      "Epoch 88: val_accuracy did not improve from 0.67241\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.7006 - loss: 0.5978 - val_accuracy: 0.5862 - val_loss: 0.6687\n",
      "Epoch 89/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6214 - loss: 0.6818\n",
      "Epoch 89: val_accuracy did not improve from 0.67241\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.6231 - loss: 0.6786 - val_accuracy: 0.6379 - val_loss: 0.6620\n",
      "Epoch 90/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6302 - loss: 0.6746\n",
      "Epoch 90: val_accuracy did not improve from 0.67241\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - accuracy: 0.6360 - loss: 0.6710 - val_accuracy: 0.6034 - val_loss: 0.6610\n",
      "Epoch 91/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6427 - loss: 0.6326\n",
      "Epoch 91: val_accuracy did not improve from 0.67241\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.6465 - loss: 0.6306 - val_accuracy: 0.5862 - val_loss: 0.6706\n",
      "Epoch 92/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6614 - loss: 0.6258\n",
      "Epoch 92: val_accuracy did not improve from 0.67241\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.6592 - loss: 0.6248 - val_accuracy: 0.5862 - val_loss: 0.6733\n",
      "Epoch 93/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6779 - loss: 0.5892\n",
      "Epoch 93: val_accuracy did not improve from 0.67241\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.6779 - loss: 0.5893 - val_accuracy: 0.5862 - val_loss: 0.6630\n",
      "Epoch 94/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6513 - loss: 0.6516\n",
      "Epoch 94: val_accuracy did not improve from 0.67241\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3s/step - accuracy: 0.6550 - loss: 0.6506 - val_accuracy: 0.6207 - val_loss: 0.6615\n",
      "Epoch 95/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6810 - loss: 0.6342\n",
      "Epoch 95: val_accuracy did not improve from 0.67241\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - accuracy: 0.6819 - loss: 0.6314 - val_accuracy: 0.6207 - val_loss: 0.6610\n",
      "Epoch 96/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.7153 - loss: 0.5908\n",
      "Epoch 96: val_accuracy did not improve from 0.67241\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4s/step - accuracy: 0.7098 - loss: 0.5959 - val_accuracy: 0.6034 - val_loss: 0.6774\n",
      "Epoch 97/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.6140 - loss: 0.6471\n",
      "Epoch 97: val_accuracy did not improve from 0.67241\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4s/step - accuracy: 0.6155 - loss: 0.6455 - val_accuracy: 0.6207 - val_loss: 0.6666\n",
      "Epoch 98/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.6626 - loss: 0.6219\n",
      "Epoch 98: val_accuracy did not improve from 0.67241\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 6s/step - accuracy: 0.6617 - loss: 0.6224 - val_accuracy: 0.5690 - val_loss: 0.6671\n",
      "Epoch 99/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.6548 - loss: 0.6465\n",
      "Epoch 99: val_accuracy did not improve from 0.67241\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4s/step - accuracy: 0.6558 - loss: 0.6422 - val_accuracy: 0.5862 - val_loss: 0.6656\n",
      "Epoch 100/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6073 - loss: 0.6365\n",
      "Epoch 100: val_accuracy did not improve from 0.67241\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - accuracy: 0.6121 - loss: 0.6354 - val_accuracy: 0.6034 - val_loss: 0.6665\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf  # 텐서플로(TensorFlow)는 딥러닝을 구현할 수 있는 구글의 오픈소스 프레임워크\n",
    "from tensorflow.keras.models import Sequential  # 레이어를 순차적으로 쌓을 수 있는 간단한 모델 형식\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization  # 완전 연결층(Dense), 과적합 방지용 드롭아웃, 학습 안정화를 위한 배치 정규화 레이어\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint  # 모델을 저장할 수 있는 콜백 함수 불러오기\n",
    "\n",
    "# train_gen과 valid_gen은 이미지 데이터 생성기라고 가정 (학습용과 검증용 이미지)\n",
    "\n",
    "img_size = (224, 224)  # 이미지의 크기를 224x224로 설정 (입력으로 통일된 크기 사용)\n",
    "channels = 3  # 컬러 이미지이므로 R, G, B 채널로 총 3개\n",
    "img_shape = (img_size[0], img_size[1], channels)  # 전체 입력 이미지의 형태 (224, 224, 3)\n",
    "\n",
    "class_count = len(list(train_gen.class_indices.keys()))  # 분류해야 할 클래스(카테고리) 수를 계산함\n",
    "\n",
    "# 사전 학습된 모델(EfficientNetB3)을 불러옴\n",
    "base_model = tf.keras.applications.EfficientNetB3(\n",
    "    include_top=False,  # 기본 모델의 마지막 분류 레이어는 제거\n",
    "    weights=\"imagenet\",  # ImageNet 데이터로 학습된 가중치를 사용\n",
    "    input_shape=img_shape,  # 입력 이미지의 크기를 지정\n",
    "    pooling='max'  # 마지막 특성 맵을 전역 최대값으로 압축\n",
    ")\n",
    "\n",
    "# 사전학습된 레이어들의 가중치를 고정시켜 학습되지 않도록 설정\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False  # 가중치 업데이트를 하지 않도록 설정 (특징 추출용으로만 사용)\n",
    "\n",
    "# 전체 모델 구성: 사전학습 모델 위에 새 레이어들을 쌓아 최종 분류 모델 생성\n",
    "model = Sequential([\n",
    "    base_model,                         # 사전학습된 베이스 모델\n",
    "    BatchNormalization(),              # 학습 안정화를 위한 배치 정규화\n",
    "    Dense(256, activation='relu'),     # 은닉층 256개 뉴런, 활성화 함수는 ReLU\n",
    "    Dropout(0.3),                      # 학습 중 30% 뉴런을 비활성화하여 과적합 방지\n",
    "    Dense(64, activation='relu'),      # 또 다른 은닉층 64개 뉴런\n",
    "    Dropout(0.3),                      # 과적합 방지를 위한 드롭아웃\n",
    "    Dense(class_count, activation='softmax')  # 출력층: 클래스 수만큼 뉴런, 확률값을 출력하기 위해 softmax 사용\n",
    "])\n",
    "\n",
    "# 모델 학습을 위한 최적화 알고리즘(Adam) 설정\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "# 모델 컴파일: 손실 함수, 최적화 알고리즘, 평가 지표 설정\n",
    "model.compile(\n",
    "    optimizer=optimizer,                     # 위에서 정의한 Adam 최적화기 사용\n",
    "    loss='categorical_crossentropy',         # 다중 분류이므로 범주형 크로스 엔트로피 사용\n",
    "    metrics=['accuracy']                     # 모델 성능을 정확도로 평가\n",
    ")\n",
    "\n",
    "# 모델을 저장할 파일 경로 지정\n",
    "filepath = 'best_model.h5'  # 가장 성능이 좋은 모델을 이 파일명으로 저장함\n",
    "\n",
    "# 검증 정확도를 기준으로 가장 좋은 모델만 저장하는 콜백 정의\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath,                # 저장 파일 경로\n",
    "    monitor='val_accuracy', # 검증 데이터의 정확도를 기준으로 판단\n",
    "    verbose=1,              # 저장 여부를 콘솔에 출력함\n",
    "    save_best_only=True,    # 정확도가 가장 높을 때만 저장\n",
    "    mode='max'              # 최대값이 가장 좋은 성능으로 간주\n",
    ")\n",
    "\n",
    "# 모델을 학습하고, 콜백을 적용하여 최적의 모델을 자동으로 저장함\n",
    "history = model.fit(\n",
    "    x=train_gen,            # 학습 데이터 생성기\n",
    "    epochs=100,              # 전체 데이터셋을 100번 반복 학습\n",
    "    verbose=1,              # 학습 과정을 자세히 출력\n",
    "    validation_data=valid_gen,  # 검증용 데이터 생성기\n",
    "    callbacks=[checkpoint]      # 체크포인트 콜백을 적용하여 모델 저장\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6da6c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: EfficientNetB3_directory\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: EfficientNetB3_directory\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'EfficientNetB3_directory'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='input_layer_5')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 2), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  2284902974672: TensorSpec(shape=(1, 1, 1, 3), dtype=tf.float32, name=None)\n",
      "  2284902976976: TensorSpec(shape=(1, 1, 1, 3), dtype=tf.float32, name=None)\n",
      "  2284902974864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284902978320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284902979088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284902976784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284902975440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284902982736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284902979856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284902984656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284902974288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284902977360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284902986000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284902984464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284902977936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284902987344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284902977168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284902976400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284902984848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284902988496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284902986192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284902989648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903320464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903317584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903321424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903318160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903324688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903325456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903320272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903323344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903319504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903326800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903327568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903324880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903327376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903331216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903329488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903328336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903330256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903322960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903322768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903728720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903729680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903327760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903322576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903732176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903731216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903728336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903734096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903727568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903733520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903737360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903735248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903734480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903738128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903738704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903738896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903737552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903733328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903740816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903742928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903742352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903742544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903731024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903738512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284904205008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284904205584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284904207120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284904204240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284904209808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284904210192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284904208272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284904202704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284904213264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284904210000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284904214800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284904211920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284904207888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284904216720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284904210768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284904217872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284904217488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284904202896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284904216912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284904218448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284904207312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284904632912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284904629072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284904633296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284904632720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284904630032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284904628880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284904635024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284904636176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284904638672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284904637520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284904629840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284904635792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284904640592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284904640400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284904640976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284904628304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284904644432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284904641936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284904643856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284904634064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284904638288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284905057552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284905055632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284905057936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284905056784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284905059280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284905059856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284905061008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284905059664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284905056976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284905054672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284905064464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284905064656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284905060432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284905056016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284905066960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284905067344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284905065616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284905067536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284905068688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284905398352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284905399888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284905069840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284905063120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284905402960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284905400464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284905406032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284905403920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284905402576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284905407568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284905406416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284905409488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284905408336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284905400272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284905410640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284905411600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284905400080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284905410448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284905402384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284905406224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284905414480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284905413136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284905412368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284905411216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284905974480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284905975248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284905975440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284905973136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284905978896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284905977168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284905980816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284905979664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284905971984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284905981776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284905982736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284905980432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284905982160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284905974864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284905986192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284905977552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284905984464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284905985808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284905986000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284906431888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284906432272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284905987536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284905983696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284906434000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284906435920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284906430928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284906436304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284906431696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284906437648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284906438032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284906435344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284906440528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284906432464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284906442256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284906445136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284906442832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284906440336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284906444368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284906441104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284906445328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284906445904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284906431120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284906840144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284906840720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284906846096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284906843216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284906844560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284906848016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284906848784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284906842640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284906846672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284906840336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284906851472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284906852624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284906848592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284906850128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284906849744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284906854544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284906855888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284906854928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284906846288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284856059536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284907331856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284907334352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284906852240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284906842448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284907334544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284907334928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284907332432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284907338192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284907331664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284907340304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284907342416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284907338384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284907336848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284907343952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284907342800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284907347024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284907344720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284907337424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284907346256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284907345296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284907344912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284907343760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284907338768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284902038032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284902034576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284902030736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284902037840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284902037264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284902031504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284902033616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284902033808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284902031888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284252484368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284902030544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284908200976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284902032080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284902036688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284908205776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284908204432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284908208464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284908206544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284908210192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284908201168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284908208848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284908207312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284908204048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284908212688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284908210000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284908202896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284908200016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284908200208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284253173456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284908213648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284908211344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284908203664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284908204624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284908213456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287182177744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287182183120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287182181392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287182180624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287182183504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287182180816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287182181776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287182182160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287182183888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903858448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903859216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287182182544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287182182928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903860176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903859792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903861136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903860368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903859408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903862096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903861712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903863056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903862288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903858256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903864016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903864208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903862480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903864592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903860560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903865744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903866512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903865360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903865168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903867472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903867088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903868432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903867664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903864400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903869392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903869008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903870352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903869584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903858640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903871312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903871504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903869776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903871888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903867856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903873040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903873808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903872656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903872464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903873616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032074896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032075472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903874384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2284903871696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032076432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032076048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032077392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032076624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032074320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032078352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032078544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032076816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032078928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032074512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032080080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032080848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032079696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032079504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032081808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032081424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032082768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032082000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032078736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032083728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032083344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032084688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032083920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032074704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032085648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032085840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032084112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032086224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032082192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032087376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032088144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032086992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032086800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032089104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032088720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032090256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032089296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032086032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032089872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032238544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032239504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032087568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032238160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032240464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032240656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032238352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032241040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032238736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032242192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032242960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032241808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032241616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032243920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032243536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032244880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032244112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032240848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032245840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032245456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032246800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032246032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032239312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032247760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032247952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032246224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032248336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032244304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032249488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032250256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032249104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032248912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032251216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032250832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032252176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032251408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032248144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032253136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032252752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032254288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032253328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032242384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032253520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032249680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032402192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032403152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032402576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032404304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032405072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032403920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032403728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032406032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032405648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032406992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032406224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032402960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032407952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032407568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032408912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032408144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032403536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032409872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032410064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032408336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032410448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032406416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032411600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032412368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032411216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032411024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032413328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032412944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032414288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032413520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032410256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032415248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032414864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032416208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032415440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032404496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032417168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032417360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032415632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032413712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032417744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032598608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032599760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032417552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032599568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032600912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032600528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032601872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032601104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032599376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032602832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032602448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032603792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032603024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032598800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032604752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032604944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032603216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032605328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032601296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032606480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032607248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032606096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032605904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032608208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032607824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032609168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032608400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032605136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032610128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032609744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032611088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032610320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032598992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032612048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032612240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032610512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032612624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032608592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032613776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032614736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032613392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032613200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032613968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032762640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032763792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032612432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032763600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032764560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032765520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032763024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032764944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032765904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032767248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032766480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032768400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032766288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2287032769552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load the .h5 model\n",
    "model = tf.keras.models.load_model('best_model.h5')\n",
    "\n",
    "# Save in SavedModel format\n",
    "model.export('EfficientNetB3_directory')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaec5fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf  # 딥러닝 프레임워크인 텐서플로(TensorFlow)를 불러옴\n",
    "from tensorflow.keras.models import load_model, Model  # 저장된 모델을 불러오는 함수와 모델 클래스 사용\n",
    "from tensorflow.keras.layers import Input, Average  # 모델의 입력 레이어와 평균 연산 레이어 사용 (현재는 사용되지 않음)\n",
    "\n",
    "# 학습이 완료된 모델(best_model.h5)을 불러옴\n",
    "model = load_model('best_model.h5')  # 저장된 최적의 모델 파일을 불러와서 메모리에 로드함\n",
    "\n",
    "# 학습 데이터셋을 사용하여 성능 평가 (손실과 정확도 출력)\n",
    "train_score = model.evaluate(train_gen, steps=len(train_gen), verbose=1)\n",
    "# steps: 전체 데이터를 한 번씩 평가하기 위한 배치 수\n",
    "# verbose=1은 진행 상황을 출력하겠다는 의미\n",
    "\n",
    "# 검증 데이터셋을 사용하여 모델 성능 평가\n",
    "valid_score = model.evaluate(valid_gen, steps=len(valid_gen), verbose=1)\n",
    "\n",
    "# 테스트 데이터셋을 사용하여 최종 모델 성능 평가\n",
    "test_score = model.evaluate(test_gen, steps=len(test_gen), verbose=1)\n",
    "\n",
    "# 학습 데이터의 손실(loss) 값 출력\n",
    "print(\"Train Loss: \", train_score[0])\n",
    "# 학습 데이터의 정확도(accuracy) 출력\n",
    "print(\"Train Accuracy: \", train_score[1])\n",
    "\n",
    "# 구분선 출력\n",
    "print('-' * 20)\n",
    "\n",
    "# 검증 데이터의 손실(loss) 값 출력\n",
    "print(\"Validation Loss: \", valid_score[0])\n",
    "# 검증 데이터의 정확도 출력\n",
    "print(\"Validation Accuracy: \", valid_score[1])\n",
    "\n",
    "# 구분선 출력\n",
    "print('-' * 20)\n",
    "\n",
    "# 테스트 데이터의 손실 값 출력\n",
    "print(\"Test Loss: \", test_score[0])\n",
    "# 테스트 데이터의 정확도 출력\n",
    "print(\"Test Accuracy: \", test_score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2517bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('best_model.h5')  \n",
    "# 학습이 끝난 상태의 모델을 로드함\n",
    "\n",
    "preds = model.predict_generator(test_gen)  \n",
    "# 테스트 데이터(test_gen)를 입력으로 하여 예측 수행  \n",
    "# predict_generator는 여러 장의 이미지를 순차적으로 예측할 수 있게 해줌  \n",
    "# 결과는 각 이미지에 대한 클래스별 확률값 배열로 반환됨\n",
    "\n",
    "y_pred = np.argmax(preds, axis=1)  \n",
    "# 가장 높은 확률값을 가진 클래스의 인덱스를 뽑아냄 → 최종 예측 클래스  \n",
    "# 예: [0.1, 0.7, 0.2] → 1 (두 번째 클래스가 가장 높은 확률)\n",
    "\n",
    "print(y_pred)  \n",
    "# 예측 결과를 출력 (각 이미지가 어떤 클래스라고 판단되었는지를 숫자로 보여줌)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafb8c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools  # 반복 가능한 객체를 조합하거나 순열을 만들 수 있는 유용한 도구 모음\n",
    "import matplotlib.pyplot as plt  # 그래프를 그릴 수 있는 시각화 도구\n",
    "\n",
    "# 혼동 행렬(Confusion Matrix)을 시각화하는 함수 정의\n",
    "# cm: Confusion Matrix 데이터(행렬)\n",
    "# classes: 클래스 이름 리스트 \n",
    "# normalize: True로 설정 시, 퍼센트로 표시되도록 정규화\n",
    "# title: plot의 이름\n",
    "# cmap: 색상 맵 \n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion Matrix', cmap=plt.cm.Blues):\n",
    "    plt.figure(figsize=(10, 10))  # 그래프 크기를 10x10 인치로 설정\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)  # 행렬 데이터를 이미지처럼 시각화, 색상 맵 사용\n",
    "    plt.title(title)  # 그래프 제목 설정\n",
    "    plt.colorbar()  # 색상 기준 바(legend) 추가\n",
    "\n",
    "    tick_marks = np.arange(len(classes))  # 클래스 개수만큼 눈금 위치 생성\n",
    "    plt.xticks(tick_marks, classes, rotation=45)  # X축 눈금에 클래스 이름 표시 (45도 회전)\n",
    "    plt.yticks(tick_marks, classes)  # Y축 눈금에도 클래스 이름 표시\n",
    "\n",
    "    if normalize:\n",
    "        # normalize=True일 경우, 정규화된 비율로 행렬값을 변경\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print('Normalized Confusion Matrix')  # 정규화된 혼동 행렬이라는 안내 출력\n",
    "    else:\n",
    "        print('Confusion Matrix, Without Normalization')  # 정규화하지 않은 혼동 행렬이라는 안내 출력\n",
    "\n",
    "    print(cm)  # 실제 숫자 데이터(행렬 값) 출력\n",
    "\n",
    "    thresh = cm.max() / 2.  # 색상 대비를 위해 기준값 설정 (최댓값의 절반)\n",
    "\n",
    "    # 모든 셀에 값을 텍스트로 삽입 (값이 크면 흰 글씨, 작으면 검정 글씨)\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment='center',\n",
    "                 color='white' if cm[i, j] > thresh else 'black')\n",
    "\n",
    "    plt.tight_layout()  # 그래프 요소 간 간격 자동 조절\n",
    "    plt.ylabel('True Label')  # Y축 라벨: 실제 클래스\n",
    "    plt.xlabel('Predicted Label')  # X축 라벨: 예측한 클래스\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f0ef18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(test_gen.classes, y_pred)\n",
    "plot_confusion_matrix(cm= cm, classes= target_names, title = 'Confusion Matrix', normalize=True)\n",
    "# Classification report\n",
    "print(classification_report(test_gen.classes, y_pred, target_names= target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2858e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf  # 딥러닝 프레임워크 TensorFlow를 불러옴\n",
    "from tensorflow.keras.models import Sequential  # 레이어를 순차적으로 쌓는 간단한 모델 구조 제공\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization  # 신경망 기본 레이어들: 완전 연결, 과적합 방지, 정규화\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint  # 모델 성능이 좋을 때 자동 저장하는 기능 제공\n",
    "\n",
    "# train_gen과 valid_gen은 이미지 데이터를 배치 단위로 제공하는 데이터 생성기라고 가정\n",
    "\n",
    "img_size = (224, 224)  # 입력 이미지의 크기를 224x224 픽셀로 설정\n",
    "channels = 3  # 컬러 이미지이므로 R,G,B → 채널 수는 3\n",
    "img_shape = (img_size[0], img_size[1], channels)  # 전체 입력 형식 = (224, 224, 3)\n",
    "\n",
    "class_count = len(list(train_gen.class_indices.keys()))  \n",
    "# 학습 데이터에 있는 클래스(분류 대상)의 총 개수 계산 (예: 'apple', 'tomato' → 2)\n",
    "\n",
    "# 사전 학습된 ResNet50 모델을 불러옴 (이미 ImageNet으로 학습된 가중치 사용)\n",
    "base_model = tf.keras.applications.ResNet50(\n",
    "    include_top=False,  # 기존 분류기 레이어는 제거하고 특징 추출기만 사용\n",
    "    weights=\"imagenet\",  # ImageNet으로 학습된 가중치를 불러옴\n",
    "    input_shape=img_shape,  # 입력 이미지의 형식을 설정\n",
    "    pooling='max'  # 마지막 출력에서 전체를 하나로 압축 (전역 최대 풀링)\n",
    ")\n",
    "\n",
    "# 기존 ResNet 모델의 가중치를 고정시켜서 학습되지 않도록 설정 (특징 추출기로만 사용)\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False  # 가중치를 업데이트하지 않음\n",
    "\n",
    "# 최종 모델 구성: 사전 학습 모델 위에 새로운 레이어를 쌓음\n",
    "model = Sequential([\n",
    "    base_model,                         # ResNet50 특징 추출기\n",
    "    BatchNormalization(),              # 정규화 레이어: 학습 안정성 증가\n",
    "    Dense(256, activation='relu'),     # 완전 연결층 (뉴런 256개), 활성화 함수는 ReLU\n",
    "    Dropout(0.3),                      # 과적합 방지를 위한 드롭아웃 (30% 비활성화)\n",
    "    Dense(64, activation='relu'),      # 또 다른 완전 연결층 (뉴런 64개)\n",
    "    Dropout(0.3),                      # 다시 드롭아웃 적용\n",
    "    Dense(class_count, activation='softmax')  # 출력층: 클래스 수 만큼 뉴런, 확률 출력을 위한 softmax 사용\n",
    "])\n",
    "\n",
    "# 모델 학습을 위한 최적화 알고리즘(Adam)을 정의\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "# 모델을 학습할 준비를 함 (손실 함수, 최적화기, 평가 지표 설정)\n",
    "model.compile(\n",
    "    optimizer=optimizer,                 # Adam 최적화 알고리즘 사용\n",
    "    loss='categorical_crossentropy',     # 다중 분류 문제이므로 crossentropy 사용\n",
    "    metrics=['accuracy']                 # 모델의 성능을 정확도로 평가\n",
    ")\n",
    "\n",
    "# 모델 성능이 가장 좋을 때 저장할 파일 경로를 지정\n",
    "filepath = 'best_model_resnet.h5'  # 저장될 모델 파일명\n",
    "\n",
    "# 검증 정확도를 기준으로 가장 좋은 모델만 저장하도록 설정\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath,                 # 저장 경로\n",
    "    monitor='val_accuracy',  # 검증 데이터의 정확도를 기준으로 평가\n",
    "    verbose=1,               # 모델 저장 여부를 콘솔에 출력\n",
    "    save_best_only=True,     # 이전보다 성능이 좋을 경우에만 저장\n",
    "    mode='max'               # 정확도 최대값 기준\n",
    ")\n",
    "\n",
    "# 모델을 학습시킴 (train_gen에서 데이터를 읽어와 20회 학습)\n",
    "history = model.fit(\n",
    "    x=train_gen,             # 학습 데이터 생성기\n",
    "    epochs=100,               # 전체 데이터셋을 100번 반복 학습\n",
    "    verbose=1,               # 학습 과정 자세히 출력\n",
    "    validation_data=valid_gen,  # 검증용 데이터 생성기\n",
    "    callbacks=[checkpoint]      # 최적 성능 모델을 저장하는 콜백 포함\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08c301f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load the .h5 model\n",
    "model = tf.keras.models.load_model('best_model_resnet.h5')\n",
    "\n",
    "# Save in SavedModel format\n",
    "model.export('ResNet50_directory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8381f311",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf  # 딥러닝 프레임워크 TensorFlow를 불러옴\n",
    "from tensorflow.keras.models import load_model, Model  # 저장된 모델을 불러오거나 모델을 다룰 수 있는 클래스\n",
    "from tensorflow.keras.layers import Input, Average  # 모델 입력 설정과 여러 모델의 출력을 평균내는 레이어 (현재는 사용되지 않음)\n",
    "\n",
    "# 학습 완료된 ResNet 기반 모델(best_model_resnet.h5)을 불러옴\n",
    "model = load_model('best_model_resnet.h5')  # 이전에 저장해 둔 최고의 모델을 메모리에 불러옴\n",
    "\n",
    "# 학습 데이터셋에 대해 모델의 손실값과 정확도를 평가함\n",
    "train_score = model.evaluate(train_gen, steps=len(train_gen), verbose=1)\n",
    "# steps: 전체 학습 데이터를 모두 평가하기 위한 배치 수\n",
    "# verbose=1: 평가 과정을 자세히 출력함\n",
    "\n",
    "# 검증 데이터셋에 대해 모델 성능 평가\n",
    "valid_score = model.evaluate(valid_gen, steps=len(valid_gen), verbose=1)\n",
    "\n",
    "# 테스트 데이터셋에 대해 최종 모델 성능 평가\n",
    "test_score = model.evaluate(test_gen, steps=len(test_gen), verbose=1)\n",
    "\n",
    "# 학습 데이터에서 손실(loss) 값 출력\n",
    "print(\"Train Loss: \", train_score[0])\n",
    "# 학습 데이터에서 정확도(accuracy) 출력\n",
    "print(\"Train Accuracy: \", train_score[1])\n",
    "\n",
    "# 구분선을 출력\n",
    "print('-' * 20)\n",
    "\n",
    "# 검증 데이터에서 손실 값 출력\n",
    "print(\"Validation Loss: \", valid_score[0])\n",
    "# 검증 데이터에서 정확도 출력\n",
    "print(\"Validation Accuracy: \", valid_score[1])\n",
    "\n",
    "# 다시 구분선 출력\n",
    "print('-' * 20)\n",
    "\n",
    "# 테스트 데이터에서 손실 값 출력\n",
    "print(\"Test Loss: \", test_score[0])\n",
    "# 테스트 데이터에서 정확도 출력\n",
    "print(\"Test Accuracy: \", test_score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2666be8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('best_model_resnet.h5')  \n",
    "# 학습이 완료된 최상의 모델을 불러옴\n",
    "# 이 모델은 학습 중 성능이 가장 좋았던 상태로 저장된 파일임\n",
    "\n",
    "preds = model.predict_generator(test_gen)  \n",
    "# 테스트 데이터셋(test_gen)을 사용하여 모델의 예측 결과 생성\n",
    "# predict_generator는 배치(batch) 단위로 데이터를 불러와 예측하는 함수\n",
    "# 결과(preds)는 각 이미지에 대해 클래스별 확률값 배열로 나옴\n",
    "# 예: [[0.1, 0.8, 0.1], [0.7, 0.2, 0.1], ...]\n",
    "\n",
    "y_pred = np.argmax(preds, axis=1)  \n",
    "# 확률값 중 가장 큰 값의 인덱스를 찾아서 실제 클래스 번호로 변환\n",
    "# 위 예에서는 [1, 0]이 출력됨 (즉, 첫 번째 이미지는 클래스 1, 두 번째는 클래스 0으로 예측됨)\n",
    "\n",
    "print(y_pred)  \n",
    "# 최종 예측된 클래스 번호들을 출력\n",
    "# 예: [1 0 2 1 1 0 ...]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830ae005",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(test_gen.classes, y_pred)\n",
    "plot_confusion_matrix(cm= cm, classes= target_names, title = 'Confusion Matrix')\n",
    "# Classification report\n",
    "print(classification_report(test_gen.classes, y_pred, target_names= target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074fb25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Assuming train_gen and valid_gen are your image data generators\n",
    "\n",
    "img_size = (224, 224)\n",
    "channels = 3\n",
    "img_shape = (img_size[0], img_size[1], channels)\n",
    "class_count = len(list(train_gen.class_indices.keys()))\n",
    "\n",
    "# Create pre-trained model\n",
    "base_model = tf.keras.applications.VGG16(include_top=False, weights=\"imagenet\", input_shape=img_shape, pooling='max')\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    BatchNormalization(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "     Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(class_count, activation='softmax')\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define filepath to save the best model\n",
    "filepath = 'best_model_vgg.h5'\n",
    "\n",
    "# Create ModelCheckpoint callback to save the best model based on validation accuracy\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "# Train the model with the added callback\n",
    "history = model.fit(\n",
    "    x=train_gen,\n",
    "    epochs=100,\n",
    "    verbose=1,\n",
    "    validation_data=valid_gen,\n",
    "    callbacks=[checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b8f123",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load the .h5 model\n",
    "model = tf.keras.models.load_model('best_model_vgg.h5')\n",
    "\n",
    "# Save in SavedModel format\n",
    "model.export('VGG16_directory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9bb363",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.layers import Input, Average\n",
    "\n",
    "\n",
    "\n",
    "model= load_model('best_model_vgg.h5')\n",
    "\n",
    "\n",
    "train_score = model.evaluate(train_gen, steps= len(train_gen), verbose= 1)\n",
    "valid_score = model.evaluate(valid_gen, steps= len(valid_gen), verbose= 1)\n",
    "test_score = model.evaluate(test_gen, steps= len(test_gen), verbose= 1)\n",
    "\n",
    "print(\"Train Loss: \", train_score[0])\n",
    "print(\"Train Accuracy: \", train_score[1])\n",
    "print('-' * 20)\n",
    "print(\"Validation Loss: \", valid_score[0])\n",
    "print(\"Validation Accuracy: \", valid_score[1])\n",
    "print('-' * 20)\n",
    "print(\"Test Loss: \", test_score[0])\n",
    "print(\"Test Accuracy: \", test_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcce496f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('best_model_vgg.h5')\n",
    "preds = model.predict_generator(test_gen)\n",
    "y_pred = np.argmax(preds, axis=1)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b8e933",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(test_gen.classes, y_pred)\n",
    "plot_confusion_matrix(cm= cm, classes= target_names, title = 'Confusion Matrix')\n",
    "# Classification report\n",
    "print(classification_report(test_gen.classes, y_pred, target_names= target_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
